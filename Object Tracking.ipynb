{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Object Tracking**"
      ],
      "metadata": {
        "id": "vbitRxweIvzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.  Implement a Kalman filter to predict and update the state of an object given its measurements\n"
      ],
      "metadata": {
        "id": "_RjR-ax8I3_v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZ6AOgSmIm8M",
        "outputId": "2e9681f4-2b90-4032-f0af-28f32278acf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Position: 0.666666944444213, Velocity: 0.33333472222106486\n",
            "Predicted Position: 1.6666686111016205, Velocity: 0.6666705555356484\n",
            "Predicted Position: 2.750004010370302, Velocity: 0.833338923540879\n",
            "Predicted Position: 3.818188119695462, Velocity: 0.9090978097474491\n",
            "Predicted Position: 4.864873894217582, Velocity: 0.9459540664794636\n",
            "Predicted Position: 5.896564036052852, Velocity: 0.9655265748121687\n",
            "Predicted Position: 6.918620848074862, Velocity: 0.9767547431965324\n",
            "Predicted Position: 7.934446931591791, Velocity: 0.9836183504245745\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "class KalmanFilter:\n",
        "    def __init__(self, dt, process_noise, measurement_noise):\n",
        "        # State vector: [position, velocity]\n",
        "        self.x = np.array([[0], [0]])  # Initial state (position=0, velocity=0)\n",
        "\n",
        "        # State covariance matrix\n",
        "        self.P = np.eye(2)\n",
        "\n",
        "        # State transition matrix\n",
        "        self.F = np.array([[1, dt],  # dt is the time step\n",
        "                           [0, 1]])\n",
        "\n",
        "        # Process noise covariance matrix\n",
        "        self.Q = process_noise * np.array([[dt**4/4, dt**3/2],\n",
        "                                           [dt**3/2, dt**2]])\n",
        "\n",
        "        # Measurement matrix\n",
        "        self.H = np.array([[1, 0]])  # We only observe position\n",
        "\n",
        "        # Measurement noise covariance matrix\n",
        "        self.R = np.array([[measurement_noise]])\n",
        "\n",
        "        # Identity matrix\n",
        "        self.I = np.eye(2)\n",
        "\n",
        "    def predict(self):\n",
        "        # Predict the state\n",
        "        self.x = np.dot(self.F, self.x)\n",
        "\n",
        "        # Predict the state covariance\n",
        "        self.P = np.dot(self.F, np.dot(self.P, self.F.T)) + self.Q\n",
        "\n",
        "    def update(self, z):\n",
        "        # Measurement residual\n",
        "        y = z - np.dot(self.H, self.x)\n",
        "\n",
        "        # Residual covariance\n",
        "        S = np.dot(self.H, np.dot(self.P, self.H.T)) + self.R\n",
        "\n",
        "        # Kalman gain\n",
        "        K = np.dot(self.P, np.dot(self.H.T, np.linalg.inv(S)))\n",
        "\n",
        "        # Update the state\n",
        "        self.x = self.x + np.dot(K, y)\n",
        "\n",
        "        # Update the covariance\n",
        "        self.P = np.dot((self.I - np.dot(K, self.H)), self.P)\n",
        "\n",
        "    def get_state(self):\n",
        "        return self.x\n",
        "\n",
        "# Parameters\n",
        "dt = 1  # Time step\n",
        "process_noise = 1e-5  # Process noise\n",
        "measurement_noise = 1  # Measurement noise\n",
        "\n",
        "# Create a Kalman filter instance\n",
        "kf = KalmanFilter(dt, process_noise, measurement_noise)\n",
        "\n",
        "# Simulated measurements (positions)\n",
        "measurements = [1, 2, 3, 4, 5, 6, 7, 8]\n",
        "\n",
        "# Predict and update the Kalman filter for each measurement\n",
        "for z in measurements:\n",
        "    kf.predict()  # Predict step\n",
        "    kf.update(np.array([[z]]))  # Update step with the new measurement\n",
        "    state = kf.get_state()\n",
        "    print(f\"Predicted Position: {state[0, 0]}, Velocity: {state[1, 0]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Write a function to normalize an image array such that pixel values are scaled between 0 and 1"
      ],
      "metadata": {
        "id": "NbFXhPavJWWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def normalize_image(image):\n",
        "    \"\"\"\n",
        "    Normalize an image array to scale pixel values between 0 and 1.\n",
        "\n",
        "    Parameters:\n",
        "        image (numpy.ndarray): Input image array with pixel values.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Normalized image array with values in the range [0, 1].\n",
        "    \"\"\"\n",
        "    # Ensure the image is in float format to avoid truncation during division\n",
        "    image = image.astype(np.float32)\n",
        "\n",
        "    # Find the minimum and maximum pixel values\n",
        "    min_val = np.min(image)\n",
        "    max_val = np.max(image)\n",
        "\n",
        "    # Normalize the image\n",
        "    normalized_image = (image - min_val) / (max_val - min_val)\n",
        "\n",
        "    return normalized_image\n"
      ],
      "metadata": {
        "id": "gQXbBgnSJLs3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example image array\n",
        "image = np.array([[50, 100, 150],\n",
        "                  [200, 250, 255],\n",
        "                  [0, 75, 125]], dtype=np.uint8)\n",
        "\n",
        "# Normalize the image\n",
        "normalized_image = normalize_image(image)\n",
        "\n",
        "# Print the result\n",
        "print(\"Original Image:\\n\", image)\n",
        "print(\"Normalized Image:\\n\", normalized_image)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KkulPv3JehD",
        "outputId": "5ad958e2-550e-45a6-988d-5937ff798278"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Image:\n",
            " [[ 50 100 150]\n",
            " [200 250 255]\n",
            " [  0  75 125]]\n",
            "Normalized Image:\n",
            " [[0.19607843 0.39215687 0.5882353 ]\n",
            " [0.78431374 0.98039216 1.        ]\n",
            " [0.         0.29411766 0.49019608]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.  Create a function to generate dummy object detection data with confidence scores and bounding boxes.\n",
        "Filter the detections based on a confidence threshold"
      ],
      "metadata": {
        "id": "K9armwUNJl8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def generate_dummy_detections(num_detections=10):\n",
        "    \"\"\"\n",
        "    Generate dummy object detection data with confidence scores and bounding boxes.\n",
        "\n",
        "    Parameters:\n",
        "        num_detections (int): Number of dummy detections to generate.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries, where each dictionary represents a detection\n",
        "              with a bounding box and a confidence score.\n",
        "    \"\"\"\n",
        "    dummy_detections = []\n",
        "    for _ in range(num_detections):\n",
        "        detection = {\n",
        "            \"bounding_box\": [\n",
        "                np.random.randint(0, 100),  # x_min\n",
        "                np.random.randint(0, 100),  # y_min\n",
        "                np.random.randint(100, 200),  # x_max\n",
        "                np.random.randint(100, 200)   # y_max\n",
        "            ],\n",
        "            \"confidence\": np.random.uniform(0.0, 1.0)  # Random confidence score\n",
        "        }\n",
        "        dummy_detections.append(detection)\n",
        "    return dummy_detections\n",
        "\n",
        "def filter_detections(detections, confidence_threshold=0.5):\n",
        "    \"\"\"\n",
        "    Filter detections based on a confidence threshold.\n",
        "\n",
        "    Parameters:\n",
        "        detections (list): A list of detection dictionaries with bounding boxes and confidence scores.\n",
        "        confidence_threshold (float): The threshold for filtering detections.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of filtered detections.\n",
        "    \"\"\"\n",
        "    filtered_detections = [\n",
        "        detection for detection in detections\n",
        "        if detection[\"confidence\"] >= confidence_threshold\n",
        "    ]\n",
        "    return filtered_detections\n"
      ],
      "metadata": {
        "id": "dfJhMTnGJgkL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate dummy detections\n",
        "detections = generate_dummy_detections(num_detections=10)\n",
        "\n",
        "# Set confidence threshold\n",
        "confidence_threshold = 0.6\n",
        "\n",
        "# Filter detections\n",
        "filtered_detections = filter_detections(detections, confidence_threshold)\n",
        "\n",
        "# Display results\n",
        "print(\"Original Detections:\")\n",
        "for det in detections:\n",
        "    print(det)\n",
        "\n",
        "print(\"\\nFiltered Detections:\")\n",
        "for det in filtered_detections:\n",
        "    print(det)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRm-eP2cJuPo",
        "outputId": "906afcac-1b64-4c23-aaaf-9f62f3739f38"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Detections:\n",
            "{'bounding_box': [63, 19, 168, 190], 'confidence': 0.10752482490184534}\n",
            "{'bounding_box': [66, 32, 178, 122], 'confidence': 0.7370863995279016}\n",
            "{'bounding_box': [26, 37, 173, 144], 'confidence': 0.5466456157309278}\n",
            "{'bounding_box': [48, 92, 101, 130], 'confidence': 0.06858801561116201}\n",
            "{'bounding_box': [86, 93, 109, 115], 'confidence': 0.41038712752187145}\n",
            "{'bounding_box': [54, 44, 176, 133], 'confidence': 0.6586873270968704}\n",
            "{'bounding_box': [66, 65, 185, 102], 'confidence': 0.44116299630636213}\n",
            "{'bounding_box': [37, 25, 170, 120], 'confidence': 0.03826876573552895}\n",
            "{'bounding_box': [77, 82, 182, 164], 'confidence': 0.598034281995006}\n",
            "{'bounding_box': [4, 59, 104, 122], 'confidence': 0.8470328190176433}\n",
            "\n",
            "Filtered Detections:\n",
            "{'bounding_box': [66, 32, 178, 122], 'confidence': 0.7370863995279016}\n",
            "{'bounding_box': [54, 44, 176, 133], 'confidence': 0.6586873270968704}\n",
            "{'bounding_box': [4, 59, 104, 122], 'confidence': 0.8470328190176433}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.  Write a function that takes a list of YOLO detections and extracts a random 128-dimensional feature vector\n",
        "for each detection"
      ],
      "metadata": {
        "id": "YrTn6EFSKGQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def extract_features_from_yolo_detections(yolo_detections):\n",
        "    \"\"\"\n",
        "    Takes a list of YOLO detections and extracts a random 128-dimensional feature vector for each detection.\n",
        "\n",
        "    Parameters:\n",
        "        yolo_detections (list): A list of dictionaries, where each dictionary contains a bounding box\n",
        "                                and a confidence score for the detection.\n",
        "                                Example format:\n",
        "                                [\n",
        "                                    {\"bounding_box\": [x_min, y_min, x_max, y_max], \"confidence\": 0.85},\n",
        "                                    ...\n",
        "                                ]\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries, where each dictionary contains the original detection data\n",
        "              and a 128-dimensional feature vector.\n",
        "    \"\"\"\n",
        "    features = []\n",
        "    for detection in yolo_detections:\n",
        "        feature_vector = np.random.rand(128)  # Generate random 128-dimensional feature vector\n",
        "        detection_with_features = {\n",
        "            \"bounding_box\": detection[\"bounding_box\"],\n",
        "            \"confidence\": detection[\"confidence\"],\n",
        "            \"feature_vector\": feature_vector\n",
        "        }\n",
        "        features.append(detection_with_features)\n",
        "    return features\n"
      ],
      "metadata": {
        "id": "1xIcTpNWJwnz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example YOLO detections\n",
        "yolo_detections = [\n",
        "    {\"bounding_box\": [34, 58, 120, 170], \"confidence\": 0.92},\n",
        "    {\"bounding_box\": [10, 20, 50, 80], \"confidence\": 0.76},\n",
        "    {\"bounding_box\": [60, 40, 150, 190], \"confidence\": 0.85},\n",
        "]\n",
        "\n",
        "# Extract features\n",
        "detections_with_features = extract_features_from_yolo_detections(yolo_detections)\n",
        "\n",
        "# Display results\n",
        "for detection in detections_with_features:\n",
        "    print(f\"Bounding Box: {detection['bounding_box']}\")\n",
        "    print(f\"Confidence: {detection['confidence']}\")\n",
        "    print(f\"Feature Vector (first 5 values): {detection['feature_vector'][:5]}...\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfxgpKtqKMY3",
        "outputId": "57c0d7ce-801d-434e-f672-9da004536459"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bounding Box: [34, 58, 120, 170]\n",
            "Confidence: 0.92\n",
            "Feature Vector (first 5 values): [0.94255317 0.48709673 0.3234599  0.41207027 0.14307764]...\n",
            "\n",
            "Bounding Box: [10, 20, 50, 80]\n",
            "Confidence: 0.76\n",
            "Feature Vector (first 5 values): [0.60680957 0.7020828  0.09200547 0.14631727 0.14685044]...\n",
            "\n",
            "Bounding Box: [60, 40, 150, 190]\n",
            "Confidence: 0.85\n",
            "Feature Vector (first 5 values): [0.72995552 0.9506403  0.48880731 0.67735397 0.81778207]...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Write a function to re-identify objects by matching feature vectors based on Euclidean distance"
      ],
      "metadata": {
        "id": "gLgR5iUmKT7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def reidentify_objects(feature_vectors_query, feature_vectors_database, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Re-identify objects by matching feature vectors from a query set with a database\n",
        "    based on Euclidean distance.\n",
        "\n",
        "    Parameters:\n",
        "        feature_vectors_query (list): List of feature vectors for query objects.\n",
        "                                      Example: [np.array([...]), np.array([...]), ...]\n",
        "        feature_vectors_database (list): List of feature vectors in the database.\n",
        "                                          Example: [np.array([...]), np.array([...]), ...]\n",
        "        threshold (float): Maximum distance below which two vectors are considered a match.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of matches for each query. Each match is represented as a dictionary:\n",
        "              {\n",
        "                  \"query_index\": int,           # Index of the query vector\n",
        "                  \"matched_database_index\": int,  # Index of the matched database vector\n",
        "                  \"distance\": float              # Distance between the two vectors\n",
        "              }\n",
        "    \"\"\"\n",
        "    matches = []\n",
        "    for i, query_vector in enumerate(feature_vectors_query):\n",
        "        min_distance = float(\"inf\")\n",
        "        best_match_index = -1\n",
        "\n",
        "        for j, db_vector in enumerate(feature_vectors_database):\n",
        "            # Compute Euclidean distance\n",
        "            distance = np.linalg.norm(query_vector - db_vector)\n",
        "\n",
        "            # Update if this is the closest match so far\n",
        "            if distance < min_distance:\n",
        "                min_distance = distance\n",
        "                best_match_index = j\n",
        "\n",
        "        # Check if the match is within the acceptable threshold\n",
        "        if min_distance <= threshold:\n",
        "            matches.append({\n",
        "                \"query_index\": i,\n",
        "                \"matched_database_index\": best_match_index,\n",
        "                \"distance\": min_distance\n",
        "            })\n",
        "    return matches\n"
      ],
      "metadata": {
        "id": "qrD8mhwwKPH8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example feature vectors\n",
        "feature_vectors_query = [\n",
        "    np.random.rand(128),  # Random query feature vector\n",
        "    np.random.rand(128)\n",
        "]\n",
        "\n",
        "feature_vectors_database = [\n",
        "    np.random.rand(128),  # Random database feature vector\n",
        "    np.random.rand(128),\n",
        "    np.random.rand(128)\n",
        "]\n",
        "\n",
        "# Re-identify objects\n",
        "matches = reidentify_objects(feature_vectors_query, feature_vectors_database, threshold=10.0)\n",
        "\n",
        "# Display matches\n",
        "for match in matches:\n",
        "    print(f\"Query Index: {match['query_index']} matched with Database Index: {match['matched_database_index']}\")\n",
        "    print(f\"Distance: {match['distance']:.4f}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvy1Kpt2Kb5c",
        "outputId": "0805bb4b-a86a-4e5f-a357-9d78dbbe27e8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query Index: 0 matched with Database Index: 2\n",
            "Distance: 4.6927\n",
            "\n",
            "Query Index: 1 matched with Database Index: 1\n",
            "Distance: 4.6674\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Write a function to track object positions using YOLO detections and a Kalman Filter"
      ],
      "metadata": {
        "id": "zn37f8NfKlQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class KalmanFilter:\n",
        "    def __init__(self):\n",
        "        # State [x, y, dx, dy] (x, y are position; dx, dy are velocity)\n",
        "        self.state = np.zeros(4)\n",
        "\n",
        "        # State covariance matrix\n",
        "        self.P = np.eye(4) * 1000\n",
        "\n",
        "        # Transition matrix (assuming constant velocity model)\n",
        "        self.F = np.array([[1, 0, 1, 0],\n",
        "                           [0, 1, 0, 1],\n",
        "                           [0, 0, 1, 0],\n",
        "                           [0, 0, 0, 1]])\n",
        "\n",
        "        # Measurement matrix\n",
        "        self.H = np.array([[1, 0, 0, 0],\n",
        "                           [0, 1, 0, 0]])\n",
        "\n",
        "        # Measurement noise covariance\n",
        "        self.R = np.array([[10, 0],\n",
        "                           [0, 10]])\n",
        "\n",
        "        # Process noise covariance\n",
        "        self.Q = np.array([[1, 0, 0, 0],\n",
        "                           [0, 1, 0, 0],\n",
        "                           [0, 0, 1, 0],\n",
        "                           [0, 0, 0, 1]])\n",
        "\n",
        "    def predict(self):\n",
        "        # Predict the next state\n",
        "        self.state = np.dot(self.F, self.state)\n",
        "        self.P = np.dot(self.F, np.dot(self.P, self.F.T)) + self.Q\n",
        "\n",
        "        return self.state\n",
        "\n",
        "    def update(self, measurement):\n",
        "        # Kalman Gain\n",
        "        y = measurement - np.dot(self.H, self.state)\n",
        "        S = np.dot(self.H, np.dot(self.P, self.H.T)) + self.R\n",
        "        K = np.dot(self.P, np.dot(self.H.T, np.linalg.inv(S)))\n",
        "\n",
        "        # Update the state\n",
        "        self.state = self.state + np.dot(K, y)\n",
        "        self.P = self.P - np.dot(K, np.dot(self.H, self.P))\n",
        "\n",
        "        return self.state\n"
      ],
      "metadata": {
        "id": "K5HU6Ly8KeOn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def track_objects_with_kalman(yolo_detections, kalman_filters, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Track objects using YOLO detections and Kalman Filter.\n",
        "\n",
        "    Parameters:\n",
        "        yolo_detections (list): List of bounding boxes from YOLO detections.\n",
        "                                 Example: [(x1, y1, x2, y2), ...]\n",
        "        kalman_filters (list): List of Kalman Filter objects used to track the objects.\n",
        "        threshold (float): Threshold for distance to consider a detection as a valid match.\n",
        "\n",
        "    Returns:\n",
        "        tracked_positions (list): List of updated object positions [(x, y), ...]\n",
        "    \"\"\"\n",
        "    tracked_positions = []\n",
        "\n",
        "    # For each object in YOLO detections, perform Kalman Filter update\n",
        "    for i, detection in enumerate(yolo_detections):\n",
        "        # Get the center of the bounding box (x, y)\n",
        "        x_center = (detection[0] + detection[2]) / 2\n",
        "        y_center = (detection[1] + detection[3]) / 2\n",
        "\n",
        "        if i < len(kalman_filters):\n",
        "            # If the Kalman filter already exists for this object, update it\n",
        "            kf = kalman_filters[i]\n",
        "            prediction = kf.predict()\n",
        "            predicted_position = prediction[:2]  # predicted (x, y)\n",
        "\n",
        "            # Compute the Euclidean distance between predicted and detection\n",
        "            distance = np.linalg.norm(np.array([x_center, y_center]) - predicted_position)\n",
        "\n",
        "            if distance < threshold:\n",
        "                # Update the Kalman filter with the new detection if the distance is small\n",
        "                kf.update(np.array([x_center, y_center]))\n",
        "            else:\n",
        "                # Reset the Kalman filter for a new object if the detection is far away\n",
        "                kf = KalmanFilter()\n",
        "                kf.update(np.array([x_center, y_center]))\n",
        "                kalman_filters.append(kf)\n",
        "\n",
        "            # Get the updated position from the Kalman filter\n",
        "            updated_position = kf.state[:2]\n",
        "            tracked_positions.append(updated_position)\n",
        "        else:\n",
        "            # If there is no Kalman filter for this object, create one\n",
        "            kf = KalmanFilter()\n",
        "            kf.update(np.array([x_center, y_center]))\n",
        "            kalman_filters.append(kf)\n",
        "\n",
        "            # Get the updated position from the Kalman filter\n",
        "            updated_position = kf.state[:2]\n",
        "            tracked_positions.append(updated_position)\n",
        "\n",
        "    return tracked_positions\n"
      ],
      "metadata": {
        "id": "YCMUhkKNK1FG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulating YOLO detections: list of bounding boxes (x1, y1, x2, y2)\n",
        "yolo_detections = [\n",
        "    (100, 150, 200, 250),  # Detection 1\n",
        "    (300, 350, 400, 450),  # Detection 2\n",
        "    (500, 550, 600, 650)   # Detection 3\n",
        "]\n",
        "\n",
        "# Create Kalman filters for tracking (initially empty)\n",
        "kalman_filters = []\n",
        "\n",
        "# Track the objects across frames\n",
        "tracked_positions = track_objects_with_kalman(yolo_detections, kalman_filters)\n",
        "\n",
        "# Display the tracked positions\n",
        "for i, position in enumerate(tracked_positions):\n",
        "    print(f\"Object {i+1} tracked position: {position}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_uSEZiBK3Hc",
        "outputId": "a28d45f7-35a2-46be-9b8f-3ddfeeaf3130"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Object 1 tracked position: [148.51485149 198.01980198]\n",
            "Object 2 tracked position: [346.53465347 396.03960396]\n",
            "Object 3 tracked position: [544.55445545 594.05940594]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B9rD24NiK5Yy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}